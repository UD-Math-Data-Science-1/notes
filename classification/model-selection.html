
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.7. Model selection &#8212; Data Science 1</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"float": ["\\mathbb{F}"], "real": ["\\mathbb{R}"], "complex": ["\\mathbb{C}"], "nat": ["\\mathbb{N}"], "integer": ["\\mathbb{Z}"], "bfa": "\\mathbf{a}", "bfe": "\\mathbf{e}", "bfx": "\\mathbf{x}", "bfX": "\\mathbf{X}", "bfu": "\\mathbf{u}", "bfv": "\\mathbf{v}", "bfw": "\\mathbf{w}", "bfy": "\\mathbf{y}", "bfz": "\\mathbf{z}", "bfzero": "\\boldsymbol{0}", "bfmu": "\\boldsymbol{\\mu}", "TP": "\\text{TP}", "TN": "\\text{TN}", "FP": "\\text{FP}", "FN": "\\text{FN}", "rmn": ["\\mathbb{R}^{#1 \\times #2}", 2], "dd": ["\\frac{d #1}{d #2}", 2], "pp": ["\\frac{\\partial #1}{\\partial #2}", 2], "norm": ["\\left\\lVert \\mathstrut #1 \\right\\rVert", 1], "abs": ["\\left\\lvert \\mathstrut #1 \\right\\rvert", 1], "twonorm": ["\\norm{#1}_2", 1], "onenorm": ["\\norm{#1}_1", 1], "infnorm": ["\\norm{#1}_\\infty", 1], "innerprod": ["\\langle #1,#2 \\rangle", 2], "pr": ["^{(#1)}", 1], "diag": ["\\operatorname{diag}"], "sign": ["\\operatorname{sign}"], "dist": ["\\operatorname{dist}"], "simil": ["\\operatorname{sim}"], "ee": ["\\times 10^"], "floor": ["\\lfloor#1\\rfloor", 1], "argmin": ["\\operatorname{argmin}"], "Cov": ["\\operatorname{Cov}"], "logit": ["\\operatorname{logit}"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.8. Exercises" href="exercises.html" />
    <link rel="prev" title="3.6. Overfitting" href="overfitting.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science 1</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Data Science 1 @ UD Math
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representation/overview.html">
   1. Representation of data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/data-types.html">
     1.1. Types of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/numpy.html">
     1.2. Introduction to numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/pandas.html">
     1.3. Introduction to pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/seaborn.html">
     1.4. Introduction to seaborn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../statistics/overview.html">
   2. Descriptive statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/summary.html">
     2.1. Summary statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/split-apply-combine.html">
     2.2. Split–apply–combine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/outliers.html">
     2.3. Outliers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/correlation.html">
     2.4. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/exercises.html">
     2.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   3. Classification
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn.html">
     3.1. Using scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="performance.html">
     3.2. Classifier performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decision-trees.html">
     3.3. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nearest-neighbors.html">
     3.4. Nearest neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="svm.html">
     3.5. Support vector machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="overfitting.html">
     3.6. Overfitting
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.7. Model selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="exercises.html">
     3.8. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../regression/overview.html">
   4. Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/linear.html">
     4.1. Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/multilinear.html">
     4.2. Multilinear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regularization.html">
     4.3. Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/nonlinear.html">
     4.4. Nonlinear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/prob_class.html">
     4.5. Probabilistic classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/logistic.html">
     4.6. Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/exercises.html">
     4.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../clustering/overview.html">
   5. Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/similarity.html">
     5.1. Similarity and distance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/performance.html">
     5.2. Clustering performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/k-means.html">
     5.3. k-means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/hierarchical.html">
     5.4. Hierarchical
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/dbscan.html">
     5.5. DBSCAN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../network/overview.html">
   6. Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/networkx.html">
     6.1. Basics of NetworkX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/degree.html">
     6.2. Degree and distance
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/classification/model-selection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/classification/model-selection.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/UD-Math-Data-Science-1/notes/main?urlpath=tree/classification/model-selection.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   Cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-tuning">
   Hyperparameter tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     Grid search
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternatives-to-grid-search">
     Alternatives to grid search
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model selection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   Cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-tuning">
   Hyperparameter tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     Grid search
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternatives-to-grid-search">
     Alternatives to grid search
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="model-selection">
<h1><span class="section-number">3.7. </span>Model selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h1>
<p>Given a classification problem, we have multiple algorithms to try, and each has some free hyperparameters. Having choices is great, but how do we choose wisely? There may be considerations other than classification accuracy, such as computing resource limitations or wanting to measure the relative importance of individual features. Here, though, we limit ourselves to optimizing error, as measured using any score that is deemed relevant.</p>
<p>It seems natural to use measurements of testing error to set a goal for comparing methods optimizing hyperparameters. However, if we base hyperparameter optimization on a fixed test set, then we are effectively learning from that set! That is, the hyperparameters might become too tuned to our particular choice of the test set, creating overfitting and variance. To avoid this conundrum, we can split the data into <em>three</em> subsets, for training, <strong>validation</strong>, and testing. The validation set is used to tune hyperparameters. Once training is performed at optimal values, the test set is used to detect a lack of generalization due to hyperparameter overfitting.</p>
<div class="section" id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h2>
<p>Unfortunately, a fixed three-way split of the data effectively reduces the amount of data available for training. Alternatively, we can turn to <strong>cross-validation</strong>, in which each learner is trained multiple times, using both different training sets and different measurement sets. One popular version is <strong><span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation</strong>:</p>
<ol class="simple">
<li><p>Divide the data into training and testing sets.</p></li>
<li><p>Further divide the training data set into <span class="math notranslate nohighlight">\(k\)</span> roughly equal parts called <em>folds</em>.</p></li>
<li><p>Train the learner using folds <span class="math notranslate nohighlight">\(2,3,\ldots,k\)</span> and validate (measure) on the cases in fold 1. Then retrain using folds <span class="math notranslate nohighlight">\(1,3,\ldots,k\)</span> and validate against the cases in fold 2. Continue until each fold has served once for validation.</p></li>
<li><p>Select the optimum hyperparameters and retrain on the entire training set.</p></li>
<li><p>Assess performance using the test set.</p></li>
</ol>
<p>For example, here is how 16 elements can be split into 4 folds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span><span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">)):</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train:&quot;</span><span class="p">,</span><span class="n">train</span><span class="p">,</span><span class="s2">&quot;, test:&quot;</span><span class="p">,</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>train: [ 0  2  3  4  5  7 10 11 12 13 14 15] , test: [1 6 8 9]
train: [ 0  1  3  5  6  7  8  9 10 11 12 15] , test: [ 2  4 13 14]
train: [ 0  1  2  3  4  5  6  8  9 12 13 14] , test: [ 7 10 11 15]
train: [ 1  2  4  6  7  8  9 10 11 13 14 15] , test: [ 0  3  5 12]
</pre></div>
</div>
</div>
</div>
<p>Let’s apply cross-validation to the loans dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span><span class="p">,</span><span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">loans</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../../notes/classification/loan_clean.csv&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">loans</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;percent_funded&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">loans</span><span class="p">[</span><span class="s2">&quot;percent_funded&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">95</span>
<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A round of 6-fold cross-validation on a standardized 5NN classifier looks like the following.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span><span class="n">KFold</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">knn</span><span class="p">)</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.74293603 0.75872385 0.76254139 0.74509944 0.73629687 0.74027632]
</pre></div>
</div>
</div>
</div>
<p>The low variance across the folds is reassurance that they are representative subsets. If we perform cross-validations as we vary a hyperparameter, we get a <strong>validation curve</strong>. Here is a validation curve for the maximum depth of a decision tree classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">depths</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">err</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># for keeping results</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
    <span class="n">err</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cv</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s2">&quot;depth&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">depths</span><span class="p">,</span><span class="n">kf</span><span class="o">.</span><span class="n">n_splits</span><span class="p">),</span><span class="s2">&quot;error&quot;</span><span class="p">:</span><span class="n">err</span><span class="p">}</span> <span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">result</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;depth&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">,</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">,</span><span class="n">ci</span><span class="o">=</span><span class="s2">&quot;sd&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/model-selection_7_0.png" src="../_images/model-selection_7_0.png" />
</div>
</div>
<p>Initially the error decreases, because the shallowest decision trees don’t have much resolving power. Eventually, though, the testing error bottoms out. Past this point, the additional power being given to the trees is used only for overfitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;depth&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>error</th>
    </tr>
    <tr>
      <th>depth</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>0.192282</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.163447</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.135040</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.123976</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.118666</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.111359</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.106439</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.104283</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.096346</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.088951</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.088964</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.087710</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.087870</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.088000</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.088008</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.086926</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.086820</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.085792</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.085434</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.085807</td>
    </tr>
    <tr>
      <th>25</th>
      <td>0.085792</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The table of mean CV errors suggests using a decision tree of depth 14 on the full training set. (It decreases a little bit more after that, but the variance suggests that it’s not worth the additional risk of overfitting to seek such small gains.) We can now train the classifier on the entire training set—which, you’ll recall, was being sliced up during cross-validation—and measure performance on the reserved testing data that has so far not been touched.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;error is&quot;</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>error is 0.08124355329007327
</pre></div>
</div>
</div>
</div>
<!-- A variant called **stratified $k$-fold cross-validation** ensures that the folds have approximately the same percentage of examples in each target class as the original data has. -->
</div>
<div class="section" id="hyperparameter-tuning">
<h2>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h2>
<p>The validation curve is useful to find a good hyperparameter values, but only when there is a single hyperparameter to consider. When multiple options are available, it’s common to perform a <em>grid search</em>, in which we try cross-validated fitting using every specified combination of parameter values.</p>
<div class="section" id="grid-search">
<h3>Grid search<a class="headerlink" href="#grid-search" title="Permalink to this headline">¶</a></h3>
<p>For example, let’s work with the breast cancer dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;frame&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">cancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;target&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We start by trying decision tree classifiers in which we vary not only the maximum depth, but some other options we did not discuss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;criterion&quot;</span><span class="p">:[</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span><span class="s2">&quot;entropy&quot;</span><span class="p">],</span> 
         <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> 
         <span class="s2">&quot;min_impurity_decrease&quot;</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.02</span><span class="p">]</span> <span class="p">}</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">grid_dt</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">grid</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">grid_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">grid_dt</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span><span class="n">grid_dt</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 4, &#39;min_impurity_decrease&#39;: 0.02},
 0.9631583877556006)
</pre></div>
</div>
</div>
</div>
<p>Next, we search over kNN classifiers. We always want use standardization as a preprocessor; note how the syntax of the grid search is adapted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;kneighborsclassifier__metric&quot;</span><span class="p">:[</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span><span class="s2">&quot;manhattan&quot;</span><span class="p">],</span> 
         <span class="s2">&quot;kneighborsclassifier__n_neighbors&quot;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span> 
         <span class="s2">&quot;kneighborsclassifier__weights&quot;</span><span class="p">:[</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span><span class="s2">&quot;distance&quot;</span><span class="p">]</span> <span class="p">}</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="n">grid_knn</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">grid</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">grid_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">grid_knn</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span><span class="n">grid_knn</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;kneighborsclassifier__metric&#39;: &#39;manhattan&#39;,
  &#39;kneighborsclassifier__n_neighbors&#39;: 3,
  &#39;kneighborsclassifier__weights&#39;: &#39;uniform&#39;},
 0.9786000507953702)
</pre></div>
</div>
</div>
</div>
<p>Finally, we look at SVM classifiers. Again, these should all use the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> preprocessor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;svc__C&quot;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span> <span class="s2">&quot;svc__kernel&quot;</span><span class="p">:[</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span><span class="s2">&quot;linear&quot;</span><span class="p">]</span> <span class="p">}</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVC</span><span class="p">())</span>
<span class="n">grid_svc</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">grid</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">grid_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">grid_svc</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">grid_svc</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;svc__C&#39;: 10, &#39;svc__kernel&#39;: &#39;rbf&#39;}, 0.9839119815391992)
</pre></div>
</div>
</div>
</div>
<p>We now have champions from each of the three types of classifier. The grid search fitting process also provides access to the models trained on the best hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">cl</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">cl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best tree f1 score:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">(</span><span class="n">grid_dt</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best knn f1 score:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">(</span><span class="n">grid_knn</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best SVC f1 score:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">(</span><span class="n">grid_svc</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>best tree f1 score: 0.905982905982906
best knn f1 score: 0.9672131147540983
best SVC f1 score: 0.9836065573770492
</pre></div>
</div>
</div>
</div>
<p>We have a winner!</p>
<p>It may be instructive to rerun the competition above using different random seeds for the train–test split and the k-fold CV. The meaningfulness of the results is limited by their sensitivity to such choices.  Don’t let floating-point values give you a false feeling of precision!</p>
</div>
<div class="section" id="alternatives-to-grid-search">
<h3>Alternatives to grid search<a class="headerlink" href="#alternatives-to-grid-search" title="Permalink to this headline">¶</a></h3>
<p>Grid search is a brute-force approach. It is <em>embarrassingly parallel</em>, meaning that different processors can work on different locations on the grid at the same time. But it is usually too slow for large training sets, or when the search space has more than two dimensions. In such cases you can try searching over crude versions of the grid, perhaps with just part of the training data, and gradually narrow the search while using all the data. When desperate, one may try a randomized search and to guide the process with experience and intuition.</p>
<p>There are special techniques available when the hyperparameter has a regularization function (such as the slack-weighting <span class="math notranslate nohighlight">\(C\)</span> parameter in the SVM), and for certain model types. You may need to take a deep dive into the sea of knowledge (and documentation) to find these.</p>
<div style="max-width:608px"><div style="position:relative;padding-bottom:66.118421052632%"><iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&playerId=kaltura_player&entry_id=1_8f2amhv1&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_98zj3y0w" width="608" height="402" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Kaltura Player" style="position:absolute;top:0;left:0;width:100%;height:100%"></iframe></div></div></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "UD-Math-Data-Science-1/notes",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="overfitting.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3.6. </span>Overfitting</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="exercises.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.8. </span>Exercises</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tobin A. Driscoll<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <img alt='UD logo' src='_static/UDlogo-small.png'>
      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>