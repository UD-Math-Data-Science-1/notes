
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.3. Decision trees &#8212; Data Science 1</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"float": ["\\mathbb{F}"], "real": ["\\mathbb{R}"], "complex": ["\\mathbb{C}"], "nat": ["\\mathbb{N}"], "integer": ["\\mathbb{Z}"], "bfa": "\\mathbf{a}", "bfe": "\\mathbf{e}", "bfx": "\\mathbf{x}", "bfX": "\\mathbf{X}", "bfu": "\\mathbf{u}", "bfv": "\\mathbf{v}", "bfw": "\\mathbf{w}", "bfy": "\\mathbf{y}", "bfz": "\\mathbf{z}", "bfzero": "\\boldsymbol{0}", "bfmu": "\\boldsymbol{\\mu}", "TP": "\\text{TP}", "TN": "\\text{TN}", "FP": "\\text{FP}", "FN": "\\text{FN}", "rmn": ["\\mathbb{R}^{#1 \\times #2}", 2], "dd": ["\\frac{d #1}{d #2}", 2], "pp": ["\\frac{\\partial #1}{\\partial #2}", 2], "norm": ["\\left\\lVert \\mathstrut #1 \\right\\rVert", 1], "abs": ["\\left\\lvert \\mathstrut #1 \\right\\rvert", 1], "twonorm": ["\\norm{#1}_2", 1], "onenorm": ["\\norm{#1}_1", 1], "infnorm": ["\\norm{#1}_\\infty", 1], "innerprod": ["\\langle #1,#2 \\rangle", 2], "pr": ["^{(#1)}", 1], "diag": ["\\operatorname{diag}"], "sign": ["\\operatorname{sign}"], "dist": ["\\operatorname{dist}"], "simil": ["\\operatorname{sim}"], "ee": ["\\times 10^"], "floor": ["\\lfloor#1\\rfloor", 1], "argmin": ["\\operatorname{argmin}"], "Cov": ["\\operatorname{Cov}"], "logit": ["\\operatorname{logit}"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.4. Nearest neighbors" href="nearest-neighbors.html" />
    <link rel="prev" title="3.2. Classifier performance" href="performance.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science 1</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Data Science 1 @ UD Math
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representation/overview.html">
   1. Representation of data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/data-types.html">
     1.1. Types of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/numpy.html">
     1.2. Introduction to numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/pandas.html">
     1.3. Introduction to pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/seaborn.html">
     1.4. Introduction to seaborn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../statistics/overview.html">
   2. Descriptive statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/summary.html">
     2.1. Summary statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/split-apply-combine.html">
     2.2. Split–apply–combine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/outliers.html">
     2.3. Outliers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/correlation.html">
     2.4. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/exercises.html">
     2.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   3. Classification
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn.html">
     3.1. Using scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="performance.html">
     3.2. Classifier performance
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.3. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nearest-neighbors.html">
     3.4. Nearest neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="svm.html">
     3.5. Support vector machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="overfitting.html">
     3.6. Overfitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model-selection.html">
     3.7. Model selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="exercises.html">
     3.8. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../regression/overview.html">
   4. Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/linear.html">
     4.1. Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/multilinear.html">
     4.2. Multilinear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regularization.html">
     4.3. Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/nonlinear.html">
     4.4. Nonlinear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/prob_class.html">
     4.5. Probabilistic classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/logistic.html">
     4.6. Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/exercises.html">
     4.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../clustering/overview.html">
   5. Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/similarity.html">
     5.1. Similarity and distance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/performance.html">
     5.2. Clustering performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/k-means.html">
     5.3. k-means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/hierarchical.html">
     5.4. Hierarchical
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/dbscan.html">
     5.5. DBSCAN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/exercises.html">
     5.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../network/overview.html">
   6. Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/networkx.html">
     6.1. Basics of NetworkX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/degree.html">
     6.2. Degree and distance
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/classification/decision-trees.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/classification/decision-trees.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/UD-Math-Data-Science-1/notes/main?urlpath=tree/classification/decision-trees.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gini-impurity">
   Gini impurity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#partitioning">
   Partitioning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#toy-example">
   Toy example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#penguin-data">
   Penguin data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limitations">
   Limitations
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Decision trees</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gini-impurity">
   Gini impurity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#partitioning">
   Partitioning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#toy-example">
   Toy example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#penguin-data">
   Penguin data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limitations">
   Limitations
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="decision-trees">
<h1><span class="section-number">3.3. </span>Decision trees<a class="headerlink" href="#decision-trees" title="Permalink to this headline">¶</a></h1>
<p>A decision tree is much like playing “Twenty Questions.” A question is asked, and the answer reduces the possible results, leading to a new question. <strong>CART</strong> (Classification And Regression Tree) is a popular method for systematizing the idea.</p>
<p>Given samples <span class="math notranslate nohighlight">\(\bfx_1,\ldots,\bfx_n\)</span> and labels <span class="math notranslate nohighlight">\(y_1,\ldots,y_n\)</span>, the immediate goal is to partition the samples into subsets whose labels are as uniform as possible. The process is then repeated recursively on the subsets. Defining a measurement of label uniformity is a key step.</p>
<div class="section" id="gini-impurity">
<h2>Gini impurity<a class="headerlink" href="#gini-impurity" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(S\)</span> be a subset of the samples, given as a list of indices into the original set. Suppose there are <span class="math notranslate nohighlight">\(K\)</span> unique labels, which we denote <span class="math notranslate nohighlight">\(1,2,\ldots,K\)</span>. Define</p>
<div class="math notranslate nohighlight">
\[
p_k = \frac{1}{ |S| } \sum_{i\in S} \mathbb{1}_k(y_i),
\]</div>
<p>where <span class="math notranslate nohighlight">\(|S|\)</span> is the number of elements in <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(\mathbb{1}_k\)</span> is the <strong>indicator function</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbb{1}_k(t) = \begin{cases} 
  1, &amp; \text{if } t=k, \\ 
  0, &amp; \text{otherwise.}
  \end{cases}
\end{split}\]</div>
<p>In words, <span class="math notranslate nohighlight">\(p_k\)</span> is the proportion of samples in <span class="math notranslate nohighlight">\(S\)</span> that have label <span class="math notranslate nohighlight">\(k\)</span>. Then the <strong>Gini impurity</strong> is defined as</p>
<div class="math notranslate nohighlight">
\[
H(S) = \sum_{k=1}^K p_k(1-p_k).
\]</div>
<p>If one of the <span class="math notranslate nohighlight">\(p_k\)</span> is 1, then the others are all zero and <span class="math notranslate nohighlight">\(H(S)=0\)</span>. This is considered optimal. At the other extreme, if <span class="math notranslate nohighlight">\(p_k=1/K\)</span> for all <span class="math notranslate nohighlight">\(k\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
H(S) = \sum_{k=1}^K \frac{1}{K} \left(1 - \frac{1}{K} \right) = K\cdot \frac{1}{K}\cdot\frac{K-1}{K} = \frac{K-1}{K} &lt; 1.
\]</div>
<div class="proof example admonition" id="example-decision-trees-gini">
<p class="admonition-title"><span class="caption-number">Example 3.3.1 </span></p>
<div class="example-content section" id="proof-content">
<p>Suppose a set <span class="math notranslate nohighlight">\(S\)</span> has <span class="math notranslate nohighlight">\(n\)</span> members with label 1, 1 member with label 2, and 1 member with label 3. What is the Gini impurity of <span class="math notranslate nohighlight">\(S\)</span>?</p>
<details class="sphinx-bs dropdown card mb-3">
<summary class="summary-title card-header">
Solution<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">We have <span class="math notranslate nohighlight">\(p_1=n/(n+2)\)</span>, <span class="math notranslate nohighlight">\(p_2=p_3=1/(n+2)\)</span>. Hence</p>
<div class="math notranslate nohighlight">
\[\begin{split}
H(S) &amp;= \frac{n}{n+2}\left( 1 - \frac{n}{n+2} \right) + 2 \frac{1}{n+2}\left( 1 - \frac{1}{n+2} \right) \\ 
&amp;= \frac{n}{n+2}\frac{2}{n+2} + \frac{2}{n+2}\frac{n+1}{n+2} \\ 
&amp;= \frac{4n+2}{(n+2)^2}.
\end{split}\]</div>
<p class="card-text">This value is 1/2 for <span class="math notranslate nohighlight">\(n=0\)</span> and approaches zero as <span class="math notranslate nohighlight">\(n\to\infty\)</span>.</p>
</div>
</details></div>
</div></div>
<div class="section" id="partitioning">
<h2>Partitioning<a class="headerlink" href="#partitioning" title="Permalink to this headline">¶</a></h2>
<p>Now we can describe the partition process. If <span class="math notranslate nohighlight">\(j\)</span> is a dimension (feature) number and <span class="math notranslate nohighlight">\(\theta\)</span> is a numerical threshold, then the sample set can be partitioned into complementary sets <span class="math notranslate nohighlight">\(S_L\)</span>, in which <span class="math notranslate nohighlight">\(x_j \le \theta\)</span>, and <span class="math notranslate nohighlight">\(S_R\)</span>, in which <span class="math notranslate nohighlight">\(x_j &gt; \theta\)</span>. Define the <strong>total impurity</strong> of the partition to be</p>
<div class="math notranslate nohighlight">
\[
Q(j,\theta) = \lvert S\rvert\, H(S) + \lvert T \rvert \, H(T).
\]</div>
<p>Choose the <span class="math notranslate nohighlight">\((j,\theta)\)</span> that minimize <span class="math notranslate nohighlight">\(Q\)</span>, and then recursively partition <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(T\)</span>.</p>
<div class="proof example admonition" id="example-decision-trees-partition">
<p class="admonition-title"><span class="caption-number">Example 3.3.2 </span></p>
<div class="example-content section" id="proof-content">
<p>Suppose the 1D real samples <span class="math notranslate nohighlight">\(x_i=i\)</span> for <span class="math notranslate nohighlight">\(i=0,1,2,3\)</span> have labels A,B,A,B. What is the optimal partition?</p>
<details class="sphinx-bs dropdown card mb-3">
<summary class="summary-title card-header">
Solution<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">There are three ways to partition them.</p>
<ul class="simple">
<li><p class="card-text"><span class="math notranslate nohighlight">\(S=\{0\}\)</span>, <span class="math notranslate nohighlight">\(T=\{1,2,3\}\)</span>. We have <span class="math notranslate nohighlight">\(H(S)=0\)</span> and <span class="math notranslate nohighlight">\(H(T)=(2/3)(1/3)+(1/3)(2/3)=4/9\)</span>. Hence the total impurity for this partition is <span class="math notranslate nohighlight">\((1)(0) + (3)(4/9) = 4/3\)</span>.</p></li>
<li><p class="card-text"><span class="math notranslate nohighlight">\(S=\{0,1\}\)</span>, <span class="math notranslate nohighlight">\(T=\{2,3\}\)</span>. Then <span class="math notranslate nohighlight">\(H(S)=H(T)=2(1/2)(1/2)=1/2\)</span>, and the total impurity is <span class="math notranslate nohighlight">\((2)(1/2)+(2)(1/2)=2\)</span>.</p></li>
<li><p class="card-text"><span class="math notranslate nohighlight">\(S=\{0,1,2\}\)</span>, <span class="math notranslate nohighlight">\(T=\{3\}\)</span>. This arrangement is the same as the first case with <span class="math notranslate nohighlight">\(A↔B\)</span>.</p></li>
</ul>
<p class="card-text">The best partition threshold is <span class="math notranslate nohighlight">\(x\le 0\)</span> (or <span class="math notranslate nohighlight">\(x\le 2\)</span>, which is equivalent).</p>
</div>
</details></div>
</div></div>
<div class="section" id="toy-example">
<h2>Toy example<a class="headerlink" href="#toy-example" title="Permalink to this headline">¶</a></h2>
<p>We first create a toy dataset with 20 random points, with two subsets of 10 that are shifted left/right a bit.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">default_rng</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">default_rng</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">x1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="mf">0.25</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">x2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">0.25</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">,[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;x₁&quot;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s2">&quot;x₂&quot;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="n">y</span><span class="p">})</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x₁&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;x₂&quot;</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/decision-trees_1_0.png" src="../_images/decision-trees_1_0.png" />
</div>
</div>
<p>Now we create a decision tree for these samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span><span class="n">plot_tree</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">t</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">import</span> <span class="n">figure</span>
<span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span><span class="n">dpi</span><span class="o">=</span><span class="mi">160</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x₁&quot;</span><span class="p">,</span><span class="s2">&quot;x₂&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/decision-trees_3_0.png" src="../_images/decision-trees_3_0.png" />
</div>
</div>
<p>The root of the tree (at the top) shows that the best split was found at the vertical line <span class="math notranslate nohighlight">\(x_1=0.644\)</span>. To the right of that line is a Gini value of zero: 8 samples, all with label 2. Thus, any future prediction by this tree will immediately return label 2 if the first feature of the input exceeds 0.644. Otherwise, it moves to the left child node and tests whether the second feature is greater than <span class="math notranslate nohighlight">\(0.96\)</span>. This splits along a horizontal line, above which there is a single sample with label 2. And so on.</p>
<p>Notice that the bottom right node has a nonzero Gini impurity. This node could be partitioned, but the classifier was constrained to stop at a depth of 3. If a prediction ends up here, then the classifier returns label 1, which is the most likely outcome.</p>
<p>Because we can follow the decision tree’s logic step by step, we say it is highly <strong>interpretable</strong>. The transparency of the prediction algorithm is an attractive aspect of decision trees, although this advantage can weaken as the numbers of features and observations increase.</p>
</div>
<div class="section" id="penguin-data">
<h2>Penguin data<a class="headerlink" href="#penguin-data" title="Permalink to this headline">¶</a></h2>
<p>We return to the penguins. There is no need to standardize the columns for a decision tree, because each feature is considered on its own.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pen</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;penguins&quot;</span><span class="p">)</span>
<span class="n">pen</span> <span class="o">=</span> <span class="n">pen</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pen</span><span class="p">[[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span><span class="s2">&quot;bill_depth_mm&quot;</span><span class="p">,</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pen</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We get some interesting information from looking at the top levels of a decision tree trained on the full dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">import</span> <span class="n">figure</span>
<span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span><span class="n">dpi</span><span class="o">=</span><span class="mi">160</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/decision-trees_7_0.png" src="../_images/decision-trees_7_0.png" />
</div>
</div>
<p>The most determinative feature for identifying the species is the flipper length. If it exceeds 206.5 mm, then the penguin is rather likely to be a Gentoo.</p>
<p>We can measure the relative importance of each feature by comparing their total contributions to reducing the Gini index. This is known as <strong>Gini importance</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>bill_length_mm       0.381063
bill_depth_mm        0.051434
flipper_length_mm    0.553866
body_mass_g          0.013638
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Flipper length alone accounts for about half of the resolving power of the tree, followed in importance by the bill length. The other measurements apparently have little discriminative value.</p>
<p>In order to assess the effectiveness of the tree, we use the train–test paradigm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span><span class="n">classification_report</span>

<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>

<span class="n">yhat</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[39  0  0]
 [ 2  8  0]
 [ 1  0 17]]
              precision    recall  f1-score   support

      Adelie       0.93      1.00      0.96        39
   Chinstrap       1.00      0.80      0.89        10
      Gentoo       1.00      0.94      0.97        18

    accuracy                           0.96        67
   macro avg       0.98      0.91      0.94        67
weighted avg       0.96      0.96      0.95        67
</pre></div>
</div>
</div>
</div>
<p>The performance is quite good, although the Chinstrap case is hindered by the relatively low number of training examples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_tr</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adelie       107
Gentoo       101
Chinstrap     58
Name: species, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">¶</a></h2>
<p>Decision trees depend sensitively on the sample locations. A tree trained on one data subset may not do well on a new set. A small change can completely rewrite large parts of the tree, which gives a caveat about interpretation. Also, the partition algorithm, which is <em>greedy</em> by doing the best thing at the moment, does not necessarily find a globally optimal tree, or even a nearby one.</p>
<p>Here we see mediocre performance on the loan application data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loans</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;loan_clean.csv&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">loans</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;percent_funded&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">loans</span><span class="p">[</span><span class="s2">&quot;percent_funded&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">95</span>
<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 229  150]
 [  15 7550]]
              precision    recall  f1-score   support

       False       0.94      0.60      0.74       379
        True       0.98      1.00      0.99      7565

    accuracy                           0.98      7944
   macro avg       0.96      0.80      0.86      7944
weighted avg       0.98      0.98      0.98      7944
</pre></div>
</div>
</div>
</div>
<p>To deal with these issues and more, you can try a <strong>random forest</strong>, which consists of many trees trained on subsets of the original features and datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>

<span class="n">yhat</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 320   59]
 [   8 7557]]
</pre></div>
</div>
</div>
</div>
<p>The details of random forests are beyond our scope.</p>
<div style="max-width:608px"><div style="position:relative;padding-bottom:66.118421052632%"><iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&playerId=kaltura_player&entry_id=1_bodwa4gl&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_tbpg3xa8" width="608" height="402" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Kaltura Player" style="position:absolute;top:0;left:0;width:100%;height:100%"></iframe></div></div></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "UD-Math-Data-Science-1/notes",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="performance.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3.2. </span>Classifier performance</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="nearest-neighbors.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.4. </span>Nearest neighbors</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tobin A. Driscoll<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <img alt='UD logo' src='_static/UDlogo-small.png'>
      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>