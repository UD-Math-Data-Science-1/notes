{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1308246b",
   "metadata": {},
   "source": [
    "# Nearest neighbors\n",
    "\n",
    "Our first learning algorithm is conceptually simple: Given a new point to classify, survey the nearest examples and choose the most frequent class. This is called the **$k$ nearest neighbors** (KNN) algorithm, where $k$ is the number of neighboring examples to survey.\n",
    "\n",
    "## Norms\n",
    "\n",
    "The existence of \"closest\" examples means that we need to define a notion of distance in spaces of any dimension. Let $\\real^d$ be the space of vectors with $d$ real components, and let $\\bfzero$ be the vector of all zeros.\n",
    "\n",
    "```{prf:definition}\n",
    "A **norm** is a function $\\|\\bfx\\|$ on $\\real^d$ that satisfies the following properties:\n",
    "\n",
    "$$\n",
    "\\|\\bfzero\\| &= 0,  \\\\ \n",
    "\\|\\bfx\\| &> 0 \\text{ if $\\bfx$ is a nonzero vector}, \\\\ \n",
    "\\|c\\bfx\\| &= |c| \\, \\|x\\| \\text{ for any real number $c$}, \\\\ \n",
    "\\|\\bfx + \\bfy \\| &\\le \\bfx + \\bfy.\n",
    "$$\n",
    "```\n",
    "\n",
    "The last inequality above is called the **triangle inequality**. It turns out that these four characteristics are all we expect from a function that behaves like a distance. \n",
    "\n",
    "We will encounter two different norms:\n",
    "\n",
    "* The 2-norm, $\\|\\bfx\\|_2 = \\bigl(x_1^2 + x_2^2 + \\cdots + x_d^2\\bigr)^{1/2}.$\n",
    "* The 1-norm, $\\|\\bfx\\|_1 = |x_1| + |x_2| + \\cdots + |x_d|.$\n",
    "\n",
    "On the number line (i.e., $\\real^1$), the distance between two values is just the absolute value of their difference, $|x-y|$. In $\\real^d$, the distance between two vectors is the norm of their difference, $\\| \\bfx - \\bfy \\|$. \n",
    "\n",
    "The 2-norm is also called the *Euclidean norm*. It generalizes ordinary geometric distance in $\\real^2$ and $\\real^3$ and is usually considered the default. The 1-norm is sometimes called the *Manhattan norm*, because in $\\real^2$ it represents the total number of east/west and north/south moves needed between points on a grid.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "As data, we are given labeled examples $\\bfx_1,\\ldots,\\bfx_n$ in $\\real^d$. Given a new query vector $\\bfx$, find the $k$ labeled vectors closest to $\\bfx$ and choose the most frequently occurring label among them. Ties can be broken randomly.\n",
    "\n",
    "KNN divides up the feature space into domains that are dominated by nearby instances. The boundaries between those domains (called **decision boundaries**) can be fairly complicated, though, as shown in the animation below. \n",
    "\n",
    "```{raw} html\n",
    "<video width=640 controls src=\"../_static/knn_demo.mp4\"></video>\n",
    "```\n",
    "\n",
    "Implementation of KNN is straightforward for small data sets, but requires care to get reasonable execution efficiency for large sets.\n",
    "\n",
    "## KNN in sklearn\n",
    "\n",
    "Let's revisit the penguins. We use `dropna` to drop any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a8c930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1    Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2    Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4    Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5    Adelie  Torgersen            39.3           20.6              190.0   \n",
       "..      ...        ...             ...            ...                ...   \n",
       "338  Gentoo     Biscoe            47.2           13.7              214.0   \n",
       "340  Gentoo     Biscoe            46.8           14.3              215.0   \n",
       "341  Gentoo     Biscoe            50.4           15.7              222.0   \n",
       "342  Gentoo     Biscoe            45.2           14.8              212.0   \n",
       "343  Gentoo     Biscoe            49.9           16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    Male  \n",
       "1         3800.0  Female  \n",
       "2         3250.0  Female  \n",
       "4         3450.0  Female  \n",
       "5         3650.0    Male  \n",
       "..           ...     ...  \n",
       "338       4925.0  Female  \n",
       "340       4850.0  Female  \n",
       "341       5750.0    Male  \n",
       "342       5200.0  Female  \n",
       "343       5400.0    Male  \n",
       "\n",
       "[333 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins = penguins.dropna()\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0032989",
   "metadata": {},
   "source": [
    "The data set has four quantitative columns that we use as features, and the species name is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2ea46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]\n",
    "X = penguins[col]\n",
    "y = penguins[\"species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df304e",
   "metadata": {},
   "source": [
    "Scikit-learn plays nicely with pandas, so we don't have to translate the data into new structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ad1625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530448f",
   "metadata": {},
   "source": [
    "We can manually find the neighbors of a new vector. However, we have to make the query in the form of a data frame, since that is how the training data was provided. Here we make a query frame for values very close to the ones in the first row of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac579e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 143,  53, 100, 153])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = pd.DataFrame([[39,19,180,3750]],columns=X.columns)\n",
    "dist,idx = knn.kneighbors(query)\n",
    "idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f999678",
   "metadata": {},
   "source": [
    "As you see above, the first point (index 0) was the closest, followed by four others. We can look up the labels of these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ea3f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Adelie\n",
       "143       Adelie\n",
       "53        Adelie\n",
       "100       Adelie\n",
       "153    Chinstrap\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[idx[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc622a3",
   "metadata": {},
   "source": [
    "By a vote of 4–1, the classifier should choose Adelie as the result at this location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517fd1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelie'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952f820",
   "metadata": {},
   "source": [
    "Note that some data points can be outvoted by their neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa74f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "['Adelie' 'Adelie' 'Chinstrap' 'Adelie' 'Chinstrap']\n",
      "\n",
      "Data:\n",
      "['Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie']\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted:\")\n",
    "print(knn.predict(X.loc[:5,:]))\n",
    "\n",
    "print(\"\\nData:\")\n",
    "print(y[:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a728ae9",
   "metadata": {},
   "source": [
    "Here we split into training and test sets to gauge the performance of the classifier The `classification_report` function creates a summary of some of the important metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e08de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  4  1]\n",
      " [11  5  0]\n",
      " [ 2  0 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.66      0.83      0.74        30\n",
      "   Chinstrap       0.56      0.31      0.40        16\n",
      "      Gentoo       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.73        67\n",
      "   macro avg       0.72      0.68      0.69        67\n",
      "weighted avg       0.73      0.73      0.72        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size=0.2)\n",
    "knn.fit(X_tr,y_tr)\n",
    "\n",
    "yhat = knn.predict(X_te)\n",
    "print(confusion_matrix(y_te,yhat))\n",
    "print(classification_report(y_te,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd442a1b",
   "metadata": {},
   "source": [
    "<!-- To assess performance, let's apply 10-fold cross-validation to KNN learners with varying $k$.\n",
    "```{code-cell}\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "K = range(1,10)\n",
    "score_mean,score_std = [],[]\n",
    "kf = KFold(n_splits=10,shuffle=True,random_state=1)\n",
    "for k in K:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn,X,y,cv=kf)\n",
    "    score_mean.append(scores.mean())\n",
    "    score_std.append(scores.std())\n",
    "\n",
    "pd.DataFrame({\"k\":K,\"accuracy mean\":score_mean,\"accuracy std\":score_std})\n",
    "```\n",
    "\n",
    "There is no improvement here over $k=1$, in which each query just adopts the species of the nearest data vector. -->\n",
    "\n",
    "The default norm in the KNN learner is the 2-norm. To use the 1-norm instead, add `metric=\"manhattan\"` to the classifier construction call.\n",
    "\n",
    "## Standardization\n",
    "\n",
    "The values in the columns of the penguin frame are scaled quite differently. In particular, the values in the body mass column are more than 20x larger than the other columns on average. Consequently, the mass feature will dominate the distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c02cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bill_length_mm         43.992793\n",
       "bill_depth_mm          17.164865\n",
       "flipper_length_mm     200.966967\n",
       "body_mass_g          4207.057057\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03147660",
   "metadata": {},
   "source": [
    "To remedy this issue, we should transform the data into z-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee501505",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.transform( lambda x: (x-x.mean())/x.std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce2296",
   "metadata": {},
   "source": [
    "In this application, standardization makes performance dramatically better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae5188ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.97      1.00      0.98        30\n",
      "   Chinstrap       1.00      0.93      0.97        15\n",
      "      Gentoo       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           0.99        67\n",
      "   macro avg       0.99      0.98      0.98        67\n",
      "weighted avg       0.99      0.99      0.98        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Z_tr, Z_te, y_tr, y_te = train_test_split(Z,y,test_size=0.2)\n",
    "knn.fit(Z_tr,y_tr)\n",
    "\n",
    "yhat = knn.predict(Z_te)\n",
    "print(confusion_matrix(y_te,yhat))\n",
    "print(classification_report(y_te,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89dfd41",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "One inconvenience of the standardization step above is that it must be performed for any new data vector that comes along. Moreover, that standardization has to use the mean and std from our original creation of `Z`, so those values need to be tracked. \n",
    "\n",
    "The sklearn answer to this need is to create a **pipeline** that includes the transformation. Pipelines make it fairly easy to chain together data transformations, followed by a learner. The composite object acts like the original learner.\n",
    "\n",
    "As you might guess, standardization of data is so common that it is predefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ce2a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler   # converts to z-scores\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "pipe = make_pipeline(StandardScaler(),knn)\n",
    "\n",
    "pipe.fit(X_tr,y_tr)\n",
    "pipe.score(X_te,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f0e1d",
   "metadata": {},
   "source": [
    "We can look under the hood a bit. The mean and variance of each of the original data columns is stored in the first part of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456d01c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  44.1018797    17.10150376  201.11278195 4196.14661654]\n",
      "[3.04095077e+01 3.77383233e+00 1.98408333e+02 6.64855922e+05]\n"
     ]
    }
   ],
   "source": [
    "print(pipe[0].mean_)\n",
    "print(pipe[0].var_)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "source_map": [
   12,
   58,
   64,
   68,
   72,
   76,
   80,
   84,
   88,
   92,
   94,
   98,
   100,
   104,
   110,
   114,
   124,
   151,
   153,
   157,
   159,
   163,
   170,
   180,
   191,
   195
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}