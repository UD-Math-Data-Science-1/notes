
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Model selection &#8212; Data Science 1</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"float": ["\\mathbb{F}"], "real": ["\\mathbb{R}"], "complex": ["\\mathbb{C}"], "nat": ["\\mathbb{N}"], "integer": ["\\mathbb{Z}"], "bfa": "\\mathbf{a}", "bfe": "\\mathbf{e}", "bfx": "\\mathbf{x}", "bfX": "\\mathbf{X}", "bfA": "\\mathbf{A}", "bfW": "\\mathbf{W}", "bfp": "\\mathbf{p}", "bfu": "\\mathbf{u}", "bfv": "\\mathbf{v}", "bfw": "\\mathbf{w}", "bfy": "\\mathbf{y}", "bfz": "\\mathbf{z}", "bfzero": "\\boldsymbol{0}", "bfmu": "\\boldsymbol{\\mu}", "TP": "\\text{TP}", "TN": "\\text{TN}", "FP": "\\text{FP}", "FN": "\\text{FN}", "rmn": ["\\mathbb{R}^{#1 \\times #2}", 2], "dd": ["\\frac{d #1}{d #2}", 2], "pp": ["\\frac{\\partial #1}{\\partial #2}", 2], "norm": ["\\left\\lVert \\mathstrut #1 \\right\\rVert", 1], "abs": ["\\left\\lvert \\mathstrut #1 \\right\\rvert", 1], "twonorm": ["\\norm{#1}_2", 1], "onenorm": ["\\norm{#1}_1", 1], "infnorm": ["\\norm{#1}_\\infty", 1], "innerprod": ["\\langle #1,#2 \\rangle", 2], "pr": ["^{(#1)}", 1], "diag": ["\\operatorname{diag}"], "sign": ["\\operatorname{sign}"], "dist": ["\\operatorname{dist}"], "simil": ["\\operatorname{sim}"], "ee": ["\\times 10^"], "floor": ["\\lfloor#1\\rfloor", 1], "argmin": ["\\operatorname{argmin}"], "Cov": ["\\operatorname{Cov}"], "logit": ["\\operatorname{logit}"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science 1</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Data Science 1 @ UD Math
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representation/overview.html">
   1. Representation of data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/data-types.html">
     1.1. Types of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/numpy.html">
     1.2. Introduction to numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/pandas.html">
     1.3. Introduction to pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/seaborn.html">
     1.4. Introduction to seaborn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../statistics/overview.html">
   2. Descriptive statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/summary.html">
     2.1. Summary statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/split-apply-combine.html">
     2.2. Split–apply–combine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/outliers.html">
     2.3. Outliers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/correlation.html">
     2.4. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/exercises.html">
     2.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../classification/overview.html">
   3. Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/sklearn.html">
     3.1. Using scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/performance.html">
     3.2. Classifier performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/decision-trees.html">
     3.3. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/nearest-neighbors.html">
     3.4. Nearest neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/svm.html">
     3.5. Support vector machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/overfitting.html">
     3.6. Overfitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/model-selection.html">
     3.7. Model selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/exercises.html">
     3.8. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../regression/overview.html">
   4. Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/linear.html">
     4.1. Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/multilinear.html">
     4.2. Multilinear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regularization.html">
     4.3. Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/nonlinear.html">
     4.4. Nonlinear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/prob_class.html">
     4.5. Probabilistic classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/logistic.html">
     4.6. Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/exercises.html">
     4.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../clustering/overview.html">
   5. Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/similarity.html">
     5.1. Similarity and distance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/performance.html">
     5.2. Clustering performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/k-means.html">
     5.3. k-means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/hierarchical.html">
     5.4. Hierarchical clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/dbscan.html">
     5.5. DBSCAN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clustering/exercises.html">
     5.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../network/overview.html">
   6. Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/networkx.html">
     6.1. Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/small-world.html">
     6.2. Small-world networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/degree.html">
     6.3. Degree distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/community.html">
     6.4. Communities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/centrality.html">
     6.5. Centrality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../network/exercises.html">
     6.6. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/etc/model-selection-fancy.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/etc/model-selection-fancy.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/UD-Math-Data-Science-1/notes/main?urlpath=tree/etc/model-selection-fancy.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   Cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-tuning">
   Hyperparameter tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     Grid search
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternatives-to-grid-search">
     Alternatives to grid search
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model selection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   Cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-tuning">
   Hyperparameter tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     Grid search
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternatives-to-grid-search">
     Alternatives to grid search
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="model-selection">
<h1>Model selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h1>
<p>Given a classification problem, we have multiple algorithms to try, and each has some free hyperparameters. Having choices is great, but how do we choose wisely? There may be considerations other than classification accuracy, such as computing resource limitations or wanting to measure the relative importance of individual features. Here, though, we limit ourselves to optimizing error, as measured using any score that is deemed relevant.</p>
<p>It seems natural to use measurements of testing error to set a goal for comparing methods optimizing hyperparameters. However, if we base hyperparameter optimization on a fixed test set, then we are effectively learning from that set! That is, the hyperparameters might become too tuned to our particular choice of the test set, creating overfitting and variance. To avoid this conundrum, we can split the data into <em>three</em> subsets, for training, <strong>validation</strong>, and testing. The validation set is used to tune hyperparameters. Once training is performed at optimal values, the test set is used to detect a lack of generalization due to hyperparameter overfitting.</p>
<div class="section" id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h2>
<p>Unfortunately, a fixed three-way split of the data effectively reduces the amount of data available for training. Alternatively, we can turn to <strong>cross-validation</strong>, in which each learner is trained multiple times, using both different training sets and different measurement sets. One popular version is <strong><span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation</strong>:</p>
<ol class="simple">
<li><p>Divide the data into training and testing sets.</p></li>
<li><p>Further divide the training data set into <span class="math notranslate nohighlight">\(k\)</span> roughly equal parts called <em>folds</em>.</p></li>
<li><p>Train the learner using folds <span class="math notranslate nohighlight">\(2,3,\ldots,k\)</span> and validate (measure) on the cases in fold 1. Then retrain using folds <span class="math notranslate nohighlight">\(1,3,\ldots,k\)</span> and validate against the cases in fold 2. Continue until each fold has served once for validation.</p></li>
<li><p>Select the optimum hyperparameters and retrain on the entire training set.</p></li>
<li><p>Assess performance using the test set.</p></li>
</ol>
<p>For example, here is how 16 elements can be split into 4 folds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span><span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">)):</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train:&quot;</span><span class="p">,</span><span class="n">train</span><span class="p">,</span><span class="s2">&quot;, test:&quot;</span><span class="p">,</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>train: [ 0  2  3  4  5  7 10 11 12 13 14 15] , test: [1 6 8 9]
train: [ 0  1  3  5  6  7  8  9 10 11 12 15] , test: [ 2  4 13 14]
train: [ 0  1  2  3  4  5  6  8  9 12 13 14] , test: [ 7 10 11 15]
train: [ 1  2  4  6  7  8  9 10 11 13 14 15] , test: [ 0  3  5 12]
</pre></div>
</div>
</div>
</div>
<p>Let’s apply cross-validation to the loans dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span><span class="p">,</span><span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">loans</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../../notes/classification/loan_clean.csv&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">loans</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;percent_funded&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">loans</span><span class="p">[</span><span class="s2">&quot;percent_funded&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">95</span>
<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A round of 6-fold cross-validation on a standardized 5NN classifier looks like the following.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span><span class="n">KFold</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">knn</span><span class="p">)</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.74293603 0.75872385 0.76254139 0.74509944 0.73629687 0.74027632]
</pre></div>
</div>
</div>
</div>
<p>The low variance across the folds is reassurance that they are representative subsets. If we perform cross-validations as we vary a hyperparameter, we get a <strong>validation curve</strong>. Here is a validation experiment for the maximum depth of a decision tree classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">depths</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;depth&quot;</span><span class="p">:[],</span><span class="s2">&quot;train&quot;</span><span class="p">:[],</span><span class="s2">&quot;test&quot;</span><span class="p">:[]})</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">depths</span><span class="p">:</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">d</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">,</span><span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">results</span><span class="p">,</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;depth&quot;</span><span class="p">:</span><span class="n">d</span><span class="p">,</span>
                                              <span class="s2">&quot;train&quot;</span><span class="p">:</span><span class="mi">1</span><span class="o">-</span><span class="n">cv</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">],</span>
                                              <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="o">-</span><span class="n">cv</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span> <span class="p">})),</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Each pass through the loop creates <code class="docutils literal notranslate"><span class="pre">n_splits</span></code> new error values. These are put into a frame that is concatenated with the results from previous iterations. (This step can be slow for large frames, or if done many times.) At the end, the <code class="docutils literal notranslate"><span class="pre">results</span></code> frame contains the errors of all the folds at each depth, for both the training and test sets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">22</span><span class="p">],:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>depth</th>
      <th>train</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>0.183003</td>
      <td>0.175284</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.0</td>
      <td>0.187641</td>
      <td>0.164174</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.0</td>
      <td>0.186485</td>
      <td>0.183627</td>
    </tr>
    <tr>
      <th>10</th>
      <td>6.0</td>
      <td>0.149314</td>
      <td>0.166457</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6.0</td>
      <td>0.153786</td>
      <td>0.141299</td>
    </tr>
    <tr>
      <th>12</th>
      <td>6.0</td>
      <td>0.147215</td>
      <td>0.135228</td>
    </tr>
    <tr>
      <th>20</th>
      <td>7.0</td>
      <td>0.112886</td>
      <td>0.149740</td>
    </tr>
    <tr>
      <th>21</th>
      <td>7.0</td>
      <td>0.119385</td>
      <td>0.125424</td>
    </tr>
    <tr>
      <th>22</th>
      <td>7.0</td>
      <td>0.121189</td>
      <td>0.115155</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>To reorganize the data for plotting, we can turn the <em>train</em> and <em>test</em> headers into a variable column, indexed by depth, using <code class="docutils literal notranslate"><span class="pre">melt</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_m</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;depth&quot;</span><span class="p">],</span><span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;set&quot;</span><span class="p">,</span><span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">)</span>
<span class="n">results_m</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">22</span><span class="p">],:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>depth</th>
      <th>set</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>train</td>
      <td>0.183003</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.0</td>
      <td>train</td>
      <td>0.187641</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.0</td>
      <td>train</td>
      <td>0.186485</td>
    </tr>
    <tr>
      <th>10</th>
      <td>6.0</td>
      <td>train</td>
      <td>0.149314</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6.0</td>
      <td>train</td>
      <td>0.153786</td>
    </tr>
    <tr>
      <th>12</th>
      <td>6.0</td>
      <td>train</td>
      <td>0.147215</td>
    </tr>
    <tr>
      <th>20</th>
      <td>7.0</td>
      <td>train</td>
      <td>0.112886</td>
    </tr>
    <tr>
      <th>21</th>
      <td>7.0</td>
      <td>train</td>
      <td>0.119385</td>
    </tr>
    <tr>
      <th>22</th>
      <td>7.0</td>
      <td>train</td>
      <td>0.121189</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">results_m</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;depth&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">,</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">,</span><span class="n">ci</span><span class="o">=</span><span class="s2">&quot;sd&quot;</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s2">&quot;set&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/model-selection-fancy_12_0.png" src="../_images/model-selection-fancy_12_0.png" />
</div>
</div>
<p>Initially the error decreases, because the shallowest decision trees don’t have much resolving power. Eventually, though, the testing error bottoms out. Past this point, the additional power being given to the trees is used only for overfitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;depth&quot;</span><span class="p">)[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>depth
5.0     0.192282
6.0     0.163447
7.0     0.135040
8.0     0.123976
9.0     0.118666
10.0    0.111359
11.0    0.106439
12.0    0.104283
13.0    0.096346
14.0    0.088951
15.0    0.088964
16.0    0.087710
17.0    0.087870
18.0    0.088000
19.0    0.088008
20.0    0.086926
21.0    0.086820
22.0    0.085792
23.0    0.085434
24.0    0.085807
25.0    0.085792
Name: test, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The table of mean CV errors suggests using a decision tree of depth 14 on the full training set. (It decreases a little bit more after that, but the variance suggests that it’s not worth the additional risk of overfitting to seek such small gains.) We can now train the classifier on the entire training set—which, you’ll recall, was being sliced up during cross-validation—and measure performance on the reserved testing data that has so far not been touched.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;error is&quot;</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>error is 0.08124355329007327
</pre></div>
</div>
</div>
</div>
<!-- A variant called **stratified $k$-fold cross-validation** ensures that the folds have approximately the same percentage of examples in each target class as the original data has. -->
</div>
<div class="section" id="hyperparameter-tuning">
<h2>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h2>
<p>The validation curve is useful to find a good hyperparameter values, but only when there is a single hyperparameter to consider. When multiple options are available, it’s common to perform a <em>grid search</em>, in which we try cross-validated fitting using every specified combination of parameter values.</p>
<div class="section" id="grid-search">
<h3>Grid search<a class="headerlink" href="#grid-search" title="Permalink to this headline">¶</a></h3>
<p>For example, let’s work with the breast cancer dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;frame&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">cancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;target&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We start by trying decision tree classifiers in which we vary not only the maximum depth, but some other options we did not discuss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;criterion&quot;</span><span class="p">:[</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span><span class="s2">&quot;entropy&quot;</span><span class="p">],</span> 
         <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> 
         <span class="s2">&quot;min_impurity_decrease&quot;</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.02</span><span class="p">]</span> <span class="p">}</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">grid_dt</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">grid</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">grid_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">grid_dt</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span><span class="n">grid_dt</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 4, &#39;min_impurity_decrease&#39;: 0.02},
 0.9631583877556006)
</pre></div>
</div>
</div>
</div>
<p>Next, we search over kNN classifiers. We always want use standardization as a preprocessor; note how the syntax of the grid search is adapted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;kneighborsclassifier__metric&quot;</span><span class="p">:[</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span><span class="s2">&quot;manhattan&quot;</span><span class="p">],</span> 
         <span class="s2">&quot;kneighborsclassifier__n_neighbors&quot;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span> 
         <span class="s2">&quot;kneighborsclassifier__weights&quot;</span><span class="p">:[</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span><span class="s2">&quot;distance&quot;</span><span class="p">]</span> <span class="p">}</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="n">grid_knn</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">grid</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">grid_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">grid_knn</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span><span class="n">grid_knn</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;kneighborsclassifier__metric&#39;: &#39;manhattan&#39;,
  &#39;kneighborsclassifier__n_neighbors&#39;: 3,
  &#39;kneighborsclassifier__weights&#39;: &#39;uniform&#39;},
 0.9786000507953702)
</pre></div>
</div>
</div>
</div>
<p>Finally, we look at SVM classifiers. Again, these should all use the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> preprocessor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;svc__C&quot;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span> <span class="s2">&quot;svc__kernel&quot;</span><span class="p">:[</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span><span class="s2">&quot;linear&quot;</span><span class="p">]</span> <span class="p">}</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVC</span><span class="p">())</span>
<span class="n">grid_svc</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span><span class="n">grid</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">grid_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">grid_svc</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">grid_svc</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;svc__C&#39;: 10, &#39;svc__kernel&#39;: &#39;rbf&#39;}, 0.9839119815391992)
</pre></div>
</div>
</div>
</div>
<p>We now have champions from each of the three types of classifier. The grid search fitting process also provides access to the models trained on the best hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">cl</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">cl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best tree f1 score:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">(</span><span class="n">grid_dt</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best knn f1 score:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">(</span><span class="n">grid_knn</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best SVC f1 score:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">(</span><span class="n">grid_svc</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>best tree f1 score: 0.905982905982906
best knn f1 score: 0.9672131147540983
best SVC f1 score: 0.9836065573770492
</pre></div>
</div>
</div>
</div>
<p>We have a winner!</p>
<p>It may be instructive to rerun the competition above using different random seeds for the train–test split and the k-fold CV. The meaningfulness of the results is limited by their sensitivity to such choices.  Don’t let floating-point values give you a false feeling of precision!</p>
</div>
<div class="section" id="alternatives-to-grid-search">
<h3>Alternatives to grid search<a class="headerlink" href="#alternatives-to-grid-search" title="Permalink to this headline">¶</a></h3>
<p>Grid search is a brute-force approach. It is <em>embarrassingly parallel</em>, meaning that different processors can work on different locations on the grid at the same time. But it is usually too slow for large training sets, or when the search space has more than two dimensions. In such cases you can try searching over crude versions of the grid, perhaps with just part of the training data, and gradually narrow the search while using all the data. When desperate, one may try a randomized search and to guide the process with experience and intuition.</p>
<p>There are special techniques available when the hyperparameter has a regularization function (such as the slack-weighting <span class="math notranslate nohighlight">\(C\)</span> parameter in the SVM), and for certain model types. You may need to take a deep dive into the sea of knowledge (and documentation) to find these.</p>
<div style="max-width:608px"><div style="position:relative;padding-bottom:66.118421052632%"><iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/2358381/sp/235838100/embedIframeJs/uiconf_id/43030021/partner_id/2358381?iframeembed=true&playerId=kaltura_player&entry_id=1_8f2amhv1&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_98zj3y0w" width="608" height="402" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Kaltura Player" style="position:absolute;top:0;left:0;width:100%;height:100%"></iframe></div></div></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "UD-Math-Data-Science-1/notes",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./etc"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tobin A. Driscoll<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <img alt='UD logo' src='_static/UDlogo-small.png'>
      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>