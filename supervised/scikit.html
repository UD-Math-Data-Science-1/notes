
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.1. Using scikit-learn &#8212; Data Science 1</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"float": ["\\mathbb{F}"], "real": ["\\mathbb{R}"], "complex": ["\\mathbb{C}"], "nat": ["\\mathbb{N}"], "integer": ["\\mathbb{Z}"], "bfx": "\\mathbf{x}", "bfX": "\\mathbf{X}", "bfy": "\\mathbf{y}", "bfz": "\\mathbf{z}", "rmn": ["\\mathbb{R}^{#1 \\times #2}", 2], "dd": ["\\frac{d #1}{d #2}", 2], "pp": ["\\frac{\\partial #1}{\\partial #2}", 2], "norm": ["\\| #1 \\|", 1], "twonorm": ["\\| #1 \\|_2", 1], "onenorm": ["\\| #1 \\|_1", 1], "infnorm": ["\\| #1 \\|_\\infty", 1], "innerprod": ["\\langle #1,#2 \\rangle", 2], "pr": ["^{(#1)}", 1], "diag": ["\\operatorname{diag}"], "sign": ["\\operatorname{sign}"], "ee": ["\\times 10^"], "floor": ["\\lfloor#1\\rfloor", 1], "argmin": ["\\operatorname{argmin}"], "Cov": ["\\operatorname{Cov}"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.2. The train–test paradigm" href="train-test.html" />
    <link rel="prev" title="3. Supervised learning" href="overview.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science 1</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Data Science 1 @ UD Math
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../representation/overview.html">
   1. Representation of data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/data-types.html">
     1.1. Types of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/pandas.html">
     1.2. Introduction to pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/split-apply-combine.html">
     1.3. Split–apply–combine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../representation/seaborn.html">
     1.4. Introduction to seaborn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../statistics/overview.html">
   2. Descriptive statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/exploratory.html">
     2.1. Exploratory analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/distributions.html">
     2.2. Continuous distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../statistics/correlation.html">
     2.3. Correlation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   3. Supervised learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.1. Using scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="train-test.html">
     3.2. The train–test paradigm
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/supervised/scikit.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/supervised/scikit.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/UD-Math-Data-Science-1/notes/main?urlpath=tree/supervised/scikit.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-classifier-performance">
   Measuring classifier performance
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <!-- Table of contents that is only displayed when printing the page -->
    <div id="jb-print-docs-body" class="onlyprint">
        <h1>Using scikit-learn</h1>
        <!-- Table of contents -->
        <div id="print-main-content" class="row">
            <div class="col-12 col-md-12 pl-md-5 pr-md-5">
            <div id="jb-print-toc">
                
                <div>
                    <h2> Contents </h2>
                </div>
                <nav aria-label="Page">
                    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-classifier-performance">
   Measuring classifier performance
  </a>
 </li>
</ul>

                </nav>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="using-scikit-learn">
<h1><span class="section-number">3.1. </span>Using scikit-learn<a class="headerlink" href="#using-scikit-learn" title="Permalink to this headline">¶</a></h1>
<p>As a data set, we use loan applications on a crowdfunding site. Each feature vector is of length 15, indicating factors such as the amount requested, the interest rate, the applicant’s annual income, etc. The goal is to predict whether the loan is at least partly funded.</p>
<p>In order to work with vectors and matrices, which are both types of arrays, we will use the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;feature matrix has shape&quot;</span><span class="p">,</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;labels.csv&quot;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label vector has shape&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>feature matrix has shape (4140, 15)
label vector has shape (4140,)
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the first 5 features of the first instance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3.600e+03, 2.375e+03, 7.631e+01, 3.000e+04, 1.504e+01])
</pre></div>
</div>
</div>
</div>
<p>And here are the last 6 labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-1., -1., -1., -1., -1., -1.])
</pre></div>
</div>
</div>
</div>
<p>A label <span class="math notranslate nohighlight">\(-1\)</span> indicates that the loan was funded, while <span class="math notranslate nohighlight">\(1\)</span> indicates that it was rejected.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> package to get familiar with classifiers. There are three main activities in this package:</p>
<ul class="simple">
<li><p><strong>fit</strong>, to train the classifier</p></li>
<li><p><strong>predict</strong>, to apply the classifier</p></li>
<li><p><strong>transform</strong>, to modify the data</p></li>
</ul>
<p>Let’s try a classifier whose characteristics we will explain in a future section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span> <span class="k">as</span> <span class="n">nbr</span> 
<span class="n">knn</span> <span class="o">=</span> <span class="n">nbr</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>   <span class="c1"># specification</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>   <span class="c1"># training</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>   <span class="c1"># prediction</span>

<span class="n">yhat</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-1., -1., -1., -1., -1., -1.])
</pre></div>
</div>
</div>
</div>
<p>Compared to the original labels above, so far, so good. How often is the classifier correct? We simply count up the number of correctly predicted labels and then divide by the total number of labels, <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">yhat</span><span class="o">==</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>   <span class="c1"># or, acc = knn.score(X,y)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy is </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy is 83.2%
</pre></div>
</div>
</div>
</div>
<p>Is that good? That turns out to be a complicated question. The vast majority of loans were funded:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">funded</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="o">==-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">funded</span><span class="o">/</span><span class="n">n</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> were funded&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>81.6% were funded
</pre></div>
</div>
</div>
</div>
<p>Therefore, an algorithm that simply “predicted” funding every loan would do nearly as well as ours!</p>
<div class="section" id="measuring-classifier-performance">
<h2>Measuring classifier performance<a class="headerlink" href="#measuring-classifier-performance" title="Permalink to this headline">¶</a></h2>
<p>To fully understand the performance of a classifier, we have to account for four cases:</p>
<ul class="simple">
<li><p>True positives (TP): Predicts “yes”, actually is “yes”</p></li>
<li><p>False positives (FP): Predicts “yes”, actually is “no”</p></li>
<li><p>True negatives (TN): Predicts “no”, actually is “no”</p></li>
<li><p>False negatives (FN): Predicts “no”, actually is “yes”</p></li>
</ul>
<p>The four cases correspond to a 2×2 table according to the states of the prediction and <em>ground truth</em>, which is the accepted correct value. The table can be filled with counts or percentages of tested instances, to create a <strong>confusion matrix</strong>, as illustrated in <a class="reference internal" href="#fig-supervised-confusion"><span class="std std-numref">Fig. 3.1.1</span></a>.</p>
<div class="figure align-default" id="fig-supervised-confusion">
<img alt="../_images/confusion.svg" src="../_images/confusion.svg" /><p class="caption"><span class="caption-number">Fig. 3.1.1 </span><span class="caption-text">Confusion matrix</span><a class="headerlink" href="#fig-supervised-confusion" title="Permalink to this image">¶</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">lbl</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fund&quot;</span><span class="p">,</span><span class="s2">&quot;reject&quot;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">display_labels</span><span class="o">=</span><span class="n">lbl</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8d105af100&gt;
</pre></div>
</div>
<img alt="../_images/scikit_13_1.png" src="../_images/scikit_13_1.png" />
</div>
</div>
<p>Hence there are 3370 true positives (funded) and 73 true negatives (rejected). Therefore, the <strong>accuracy</strong> is</p>
<div class="math notranslate nohighlight">
\[
\newcommand{TP}{\text{TP}}
\newcommand{FP}{\text{FP}}
\newcommand{TN}{\text{TN}}
\newcommand{FN}{\text{FN}}
\text{accuracy} = \frac{\TP + \TN}{n} = \frac{3443}{4140} = 0.83164\ldots,
\]</div>
<p>i.e., 83.2%. However, there are four other quantities defined by putting a “number correct” value in the numerator and a sum of a row or column in the denominator:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\text{recall (aka sensitvity)} &amp;= \frac{\TP}{\TP + \FN} \\[2mm]
\text{specificity} &amp;= \frac{\TN}{\TN + \FP} \\[2mm] 
\text{precision} &amp;= \frac{\TP}{\TP + \FP} \\[2mm] 
\text{negative predictive value (NPV)} &amp;= \frac{\TN}{\TN + \FN} \\ 
\end{split}\]</div>
<p>In words, these metrics answer the following questions:</p>
<ul class="simple">
<li><p><strong>recall</strong> How often are actual “yes” cases predicted correctly?</p></li>
<li><p><strong>specificity</strong> How often are actual “no” cases predicted correctly?</p></li>
<li><p><strong>precision</strong> How often are the “yes” predictions correct?</p></li>
<li><p><strong>NPV</strong> How often are the “no” predictions correct?</p></li>
</ul>
<p>For our loan classifier, here are the scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;recall = </span><span class="si">{</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;specificity = </span><span class="si">{</span><span class="n">TN</span><span class="o">/</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;precision = </span><span class="si">{</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NPV = </span><span class="si">{</span><span class="n">TN</span><span class="o">/</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>recall = 99.8%
specificity = 9.6%
precision = 83.0%
NPV = 91.2%
</pre></div>
</div>
</div>
</div>
<p>The recall is almost perfect: virtually nobody who should get a loan will go away disappointed. However, the low specificity would be concerning to those doing the funding, because nine in ten applicants who should be denied will be funded as well.</p>
<p>We could make the performance seemingly a lot better by changing how the classifier is set up.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">nbr</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>  
<span class="n">yhat</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 

<span class="n">C</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[3377    0]
 [   0  763]]
</pre></div>
</div>
</div>
</div>
<p>By every one of our measures, this is perfect performance! However, our enthusiasm has to be kept in check. Thus far we are only testing the performance on the training data. Will it work well on new instances? We consider that question next.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "UD-Math-Data-Science-1/notes",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./supervised"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </div>
        </div>
    </div>
    <div id="main-content" class="row noprint">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="using-scikit-learn">
<h1><span class="section-number">3.1. </span>Using scikit-learn<a class="headerlink" href="#using-scikit-learn" title="Permalink to this headline">¶</a></h1>
<p>As a data set, we use loan applications on a crowdfunding site. Each feature vector is of length 15, indicating factors such as the amount requested, the interest rate, the applicant’s annual income, etc. The goal is to predict whether the loan is at least partly funded.</p>
<p>In order to work with vectors and matrices, which are both types of arrays, we will use the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;feature matrix has shape&quot;</span><span class="p">,</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;labels.csv&quot;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label vector has shape&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>feature matrix has shape (4140, 15)
label vector has shape (4140,)
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the first 5 features of the first instance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3.600e+03, 2.375e+03, 7.631e+01, 3.000e+04, 1.504e+01])
</pre></div>
</div>
</div>
</div>
<p>And here are the last 6 labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-1., -1., -1., -1., -1., -1.])
</pre></div>
</div>
</div>
</div>
<p>A label <span class="math notranslate nohighlight">\(-1\)</span> indicates that the loan was funded, while <span class="math notranslate nohighlight">\(1\)</span> indicates that it was rejected.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> package to get familiar with classifiers. There are three main activities in this package:</p>
<ul class="simple">
<li><p><strong>fit</strong>, to train the classifier</p></li>
<li><p><strong>predict</strong>, to apply the classifier</p></li>
<li><p><strong>transform</strong>, to modify the data</p></li>
</ul>
<p>Let’s try a classifier whose characteristics we will explain in a future section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span> <span class="k">as</span> <span class="n">nbr</span> 
<span class="n">knn</span> <span class="o">=</span> <span class="n">nbr</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>   <span class="c1"># specification</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>   <span class="c1"># training</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>   <span class="c1"># prediction</span>

<span class="n">yhat</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-1., -1., -1., -1., -1., -1.])
</pre></div>
</div>
</div>
</div>
<p>Compared to the original labels above, so far, so good. How often is the classifier correct? We simply count up the number of correctly predicted labels and then divide by the total number of labels, <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">yhat</span><span class="o">==</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>   <span class="c1"># or, acc = knn.score(X,y)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy is </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy is 83.2%
</pre></div>
</div>
</div>
</div>
<p>Is that good? That turns out to be a complicated question. The vast majority of loans were funded:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">funded</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="o">==-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">funded</span><span class="o">/</span><span class="n">n</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> were funded&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>81.6% were funded
</pre></div>
</div>
</div>
</div>
<p>Therefore, an algorithm that simply “predicted” funding every loan would do nearly as well as ours!</p>
<div class="section" id="measuring-classifier-performance">
<h2>Measuring classifier performance<a class="headerlink" href="#measuring-classifier-performance" title="Permalink to this headline">¶</a></h2>
<p>To fully understand the performance of a classifier, we have to account for four cases:</p>
<ul class="simple">
<li><p>True positives (TP): Predicts “yes”, actually is “yes”</p></li>
<li><p>False positives (FP): Predicts “yes”, actually is “no”</p></li>
<li><p>True negatives (TN): Predicts “no”, actually is “no”</p></li>
<li><p>False negatives (FN): Predicts “no”, actually is “yes”</p></li>
</ul>
<p>The four cases correspond to a 2×2 table according to the states of the prediction and <em>ground truth</em>, which is the accepted correct value. The table can be filled with counts or percentages of tested instances, to create a <strong>confusion matrix</strong>, as illustrated in <a class="reference internal" href="#fig-supervised-confusion"><span class="std std-numref">Fig. 3.1.1</span></a>.</p>
<div class="figure align-default" id="fig-supervised-confusion">
<img alt="../_images/confusion.svg" src="../_images/confusion.svg" /><p class="caption"><span class="caption-number">Fig. 3.1.1 </span><span class="caption-text">Confusion matrix</span><a class="headerlink" href="#fig-supervised-confusion" title="Permalink to this image">¶</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">lbl</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fund&quot;</span><span class="p">,</span><span class="s2">&quot;reject&quot;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">display_labels</span><span class="o">=</span><span class="n">lbl</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8d105af100&gt;
</pre></div>
</div>
<img alt="../_images/scikit_13_1.png" src="../_images/scikit_13_1.png" />
</div>
</div>
<p>Hence there are 3370 true positives (funded) and 73 true negatives (rejected). Therefore, the <strong>accuracy</strong> is</p>
<div class="math notranslate nohighlight">
\[
\newcommand{TP}{\text{TP}}
\newcommand{FP}{\text{FP}}
\newcommand{TN}{\text{TN}}
\newcommand{FN}{\text{FN}}
\text{accuracy} = \frac{\TP + \TN}{n} = \frac{3443}{4140} = 0.83164\ldots,
\]</div>
<p>i.e., 83.2%. However, there are four other quantities defined by putting a “number correct” value in the numerator and a sum of a row or column in the denominator:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\text{recall (aka sensitvity)} &amp;= \frac{\TP}{\TP + \FN} \\[2mm]
\text{specificity} &amp;= \frac{\TN}{\TN + \FP} \\[2mm] 
\text{precision} &amp;= \frac{\TP}{\TP + \FP} \\[2mm] 
\text{negative predictive value (NPV)} &amp;= \frac{\TN}{\TN + \FN} \\ 
\end{split}\]</div>
<p>In words, these metrics answer the following questions:</p>
<ul class="simple">
<li><p><strong>recall</strong> How often are actual “yes” cases predicted correctly?</p></li>
<li><p><strong>specificity</strong> How often are actual “no” cases predicted correctly?</p></li>
<li><p><strong>precision</strong> How often are the “yes” predictions correct?</p></li>
<li><p><strong>NPV</strong> How often are the “no” predictions correct?</p></li>
</ul>
<p>For our loan classifier, here are the scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;recall = </span><span class="si">{</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;specificity = </span><span class="si">{</span><span class="n">TN</span><span class="o">/</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;precision = </span><span class="si">{</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NPV = </span><span class="si">{</span><span class="n">TN</span><span class="o">/</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>recall = 99.8%
specificity = 9.6%
precision = 83.0%
NPV = 91.2%
</pre></div>
</div>
</div>
</div>
<p>The recall is almost perfect: virtually nobody who should get a loan will go away disappointed. However, the low specificity would be concerning to those doing the funding, because nine in ten applicants who should be denied will be funded as well.</p>
<p>We could make the performance seemingly a lot better by changing how the classifier is set up.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">nbr</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>  
<span class="n">yhat</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 

<span class="n">C</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[3377    0]
 [   0  763]]
</pre></div>
</div>
</div>
</div>
<p>By every one of our measures, this is perfect performance! However, our enthusiasm has to be kept in check. Thus far we are only testing the performance on the training data. Will it work well on new instances? We consider that question next.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "UD-Math-Data-Science-1/notes",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./supervised"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="overview.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3. </span>Supervised learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="train-test.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.2. </span>The train–test paradigm</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tobin A. Driscoll<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>